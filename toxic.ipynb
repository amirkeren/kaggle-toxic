{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing import text\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "swear_words = [\"4r5e\", \"5h1t\", \"5hit\", \"a55\", \"anal\", \"anus\", \"ar5e\", \"arrse\", \"arse\", \"ass\", \"ass-fucker\", \"asses\", \"assfucker\", \"assfukka\", \"asshole\", \"assholes\", \"asswhole\", \"a_s_s\", \"b!tch\", \"b00bs\", \"b17ch\", \"b1tch\", \"ballbag\", \"balls\", \"ballsack\", \"bastard\", \"beastial\", \"beastiality\", \"bellend\", \"bestial\", \"bestiality\", \"bi+ch\", \"biatch\", \"bitch\", \"bitcher\", \"bitchers\", \"bitches\", \"bitchin\", \"bitching\", \"bloody\", \"blow job\", \"blowjob\", \"blowjobs\", \"boiolas\", \"bollock\", \"bollok\", \"boner\", \"boob\", \"boobs\", \"booobs\", \"boooobs\", \"booooobs\", \"booooooobs\", \"breasts\", \"buceta\", \"bugger\", \"bum\", \"bunny fucker\", \"butt\", \"butthole\", \"buttmuch\", \"buttplug\", \"c0ck\", \"c0cksucker\", \"carpet muncher\", \"cawk\", \"chink\", \"cipa\", \"cl1t\", \"clit\", \"clitoris\", \"clits\", \"cnut\", \"cock\", \"cock-sucker\", \"cockface\", \"cockhead\", \"cockmunch\", \"cockmuncher\", \"cocks\", \"cocksuck\", \"cocksucked\", \"cocksucker\", \"cocksucking\", \"cocksucks\", \"cocksuka\", \"cocksukka\", \"cok\", \"cokmuncher\", \"coksucka\", \"coon\", \"cox\", \"crap\", \"cum\", \"cummer\", \"cumming\", \"cums\", \"cumshot\", \"cunilingus\", \"cunillingus\", \"cunnilingus\", \"cunt\", \"cuntlick\", \"cuntlicker\", \"cuntlicking\", \"cunts\", \"cyalis\", \"cyberfuc\", \"cyberfuck\", \"cyberfucked\", \"cyberfucker\", \"cyberfuckers\", \"cyberfucking\", \"d1ck\", \"damn\", \"dick\", \"dickhead\", \"dildo\", \"dildos\", \"dink\", \"dinks\", \"dirsa\", \"dlck\", \"dog-fucker\", \"doggin\", \"dogging\", \"donkeyribber\", \"doosh\", \"duche\", \"dyke\", \"ejaculate\", \"ejaculated\", \"ejaculates\", \"ejaculating\", \"ejaculatings\", \"ejaculation\", \"ejakulate\", \"f u c k\", \"f u c k e r\", \"f4nny\", \"fag\", \"fagging\", \"faggitt\", \"faggot\", \"faggs\", \"fagot\", \"fagots\", \"fags\", \"fanny\", \"fannyflaps\", \"fannyfucker\", \"fanyy\", \"fatass\", \"fcuk\", \"fcuker\", \"fcuking\", \"feck\", \"fecker\", \"felching\", \"fellate\", \"fellatio\", \"fingerfuck\", \"fingerfucked\", \"fingerfucker\", \"fingerfuckers\", \"fingerfucking\", \"fingerfucks\", \"fistfuck\", \"fistfucked\", \"fistfucker\", \"fistfuckers\", \"fistfucking\", \"fistfuckings\", \"fistfucks\", \"flange\", \"fook\", \"fooker\", \"fuck\", \"fucka\", \"fucked\", \"fucker\", \"fuckers\", \"fuckhead\", \"fuckheads\", \"fuckin\", \"fucking\", \"fuckings\", \"fuckingshitmotherfucker\", \"fuckme\", \"fucks\", \"fuckwhit\", \"fuckwit\", \"fudge packer\", \"fudgepacker\", \"fuk\", \"fuker\", \"fukker\", \"fukkin\", \"fuks\", \"fukwhit\", \"fukwit\", \"fux\", \"fux0r\", \"f_u_c_k\", \"gangbang\", \"gangbanged\", \"gangbangs\", \"gaylord\", \"gaysex\", \"goatse\", \"God\", \"god-dam\", \"god-damned\", \"goddamn\", \"goddamned\", \"hardcoresex\", \"hell\", \"heshe\", \"hoar\", \"hoare\", \"hoer\", \"homo\", \"hore\", \"horniest\", \"horny\", \"hotsex\", \"jack-off\", \"jackoff\", \"jap\", \"jerk-off\", \"jism\", \"jiz\", \"jizm\", \"jizz\", \"kawk\", \"knob\", \"knobead\", \"knobed\", \"knobend\", \"knobhead\", \"knobjocky\", \"knobjokey\", \"kock\", \"kondum\", \"kondums\", \"kum\", \"kummer\", \"kumming\", \"kums\", \"kunilingus\", \"l3i+ch\", \"l3itch\", \"labia\", \"lust\", \"lusting\", \"m0f0\", \"m0fo\", \"m45terbate\", \"ma5terb8\", \"ma5terbate\", \"masochist\", \"master-bate\", \"masterb8\", \"masterbat*\", \"masterbat3\", \"masterbate\", \"masterbation\", \"masterbations\", \"masturbate\", \"mo-fo\", \"mof0\", \"mofo\", \"mothafuck\", \"mothafucka\", \"mothafuckas\", \"mothafuckaz\", \"mothafucked\", \"mothafucker\", \"mothafuckers\", \"mothafuckin\", \"mothafucking\", \"mothafuckings\", \"mothafucks\", \"mother fucker\", \"motherfuck\", \"motherfucked\", \"motherfucker\", \"motherfuckers\", \"motherfuckin\", \"motherfucking\", \"motherfuckings\", \"motherfuckka\", \"motherfucks\", \"muff\", \"mutha\", \"muthafecker\", \"muthafuckker\", \"muther\", \"mutherfucker\", \"n1gga\", \"n1gger\", \"nazi\", \"nigg3r\", \"nigg4h\", \"nigga\", \"niggah\", \"niggas\", \"niggaz\", \"nigger\", \"niggers\", \"nob\", \"nob jokey\", \"nobhead\", \"nobjocky\", \"nobjokey\", \"numbnuts\", \"nutsack\", \"orgasim\", \"orgasims\", \"orgasm\", \"orgasms\", \"p0rn\", \"pawn\", \"pecker\", \"penis\", \"penisfucker\", \"phonesex\", \"phuck\", \"phuk\", \"phuked\", \"phuking\", \"phukked\", \"phukking\", \"phuks\", \"phuq\", \"pigfucker\", \"pimpis\", \"piss\", \"pissed\", \"pisser\", \"pissers\", \"pisses\", \"pissflaps\", \"pissin\", \"pissing\", \"pissoff\", \"poop\", \"porn\", \"porno\", \"pornography\", \"pornos\", \"prick\", \"pricks\", \"pron\", \"pube\", \"pusse\", \"pussi\", \"pussies\", \"pussy\", \"pussys\", \"rectum\", \"retard\", \"rimjaw\", \"rimming\", \"s hit\", \"s.o.b.\", \"sadist\", \"schlong\", \"screwing\", \"scroat\", \"scrote\", \"scrotum\", \"semen\", \"sex\", \"sh!+\", \"sh!t\", \"sh1t\", \"shag\", \"shagger\", \"shaggin\", \"shagging\", \"shemale\", \"shi+\", \"shit\", \"shitdick\", \"shite\", \"shited\", \"shitey\", \"shitfuck\", \"shitfull\", \"shithead\", \"shiting\", \"shitings\", \"shits\", \"shitted\", \"shitter\", \"shitters\", \"shitting\", \"shittings\", \"shitty\", \"skank\", \"slut\", \"sluts\", \"smegma\", \"smut\", \"snatch\", \"son-of-a-bitch\", \"spac\", \"spunk\", \"s_h_i_t\", \"t1tt1e5\", \"t1tties\", \"teets\", \"teez\", \"testical\", \"testicle\", \"tit\", \"titfuck\", \"tits\", \"titt\", \"tittie5\", \"tittiefucker\", \"titties\", \"tittyfuck\", \"tittywank\", \"titwank\", \"tosser\", \"turd\", \"tw4t\", \"twat\", \"twathead\", \"twatty\", \"twunt\", \"twunter\", \"v14gra\", \"v1gra\", \"vagina\", \"viagra\", \"vulva\", \"w00se\", \"wang\", \"wank\", \"wanker\", \"wanky\", \"whoar\", \"whore\", \"willies\", \"willy\", \"xrated\", \"xxx\"]\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOV_TOKEN = 0\n",
    "\n",
    "hypterparameters = {\n",
    "    'mean_support': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=None,\n",
    "                           filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                           lower=True,\n",
    "                           split=\" \",\n",
    "                           char_level=False)\n",
    "\n",
    "tokenizer.fit_on_texts(train.comment_text)\n",
    "tokenized_input = tokenizer.texts_to_sequences(train.comment_text.values)\n",
    "\n",
    "flat_list = [token for sublist in tokenized_input for token in sublist]\n",
    "counts = Counter(flat_list)\n",
    "oov_dict = {x : flat_list[x] for x in flat_list if flat_list[x] < hypterparameters['mean_support'] }\n",
    "\n",
    "tokenized_input = [[OOV_TOKEN if x in oov_dict else x for x in comment] for comment in tokenized_input]\n",
    "\n",
    "print(tokenized_input[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
