{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/c/8076/download/train.csv.zip\n",
    "train = pd.read_csv('data/train.csv')[:100]\n",
    "# Download from https://www.kaggle.com/c/8076/download/test.csv.zip\n",
    "test = pd.read_csv('data/test.csv')[:100]\n",
    "\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "y_train = train[classes].values\n",
    "\n",
    "train_sentences = train.comment_text.fillna('FILLNA').values\n",
    "test_sentences = test.comment_text.fillna('FILLNA').values\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(np.concatenate((train_sentences, test_sentences), axis=0))\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "maxlen = max(max(len(l) for l in train_tokenized), max(len(l) for l in test_tokenized))\n",
    "X_train = sequence.pad_sequences(train_tokenized, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(test_tokenized, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_list = [token for sublist in train_tokenized + test_tokenized for token in sublist]\n",
    "vocab_size = len(Counter(flat_list)) + 1\n",
    "\n",
    "hypterparameters = {\n",
    "    'validation_split': 0.1,\n",
    "    'is_verbose': 1,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'embedding_size': 128,\n",
    "    'keep_probability': 0.9,\n",
    "    'lstm_size': 50,\n",
    "    'dense_size': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, hypterparameters['embedding_size']))\n",
    "model.add(LSTM(hypterparameters['lstm_size'], return_sequences=True))\n",
    "model.add(LSTM(hypterparameters['lstm_size']))\n",
    "model.add(Dropout(1 - hypterparameters['keep_probability']))\n",
    "model.add(Dense(hypterparameters['dense_size'], activation='relu'))\n",
    "model.add(Dropout(1 - hypterparameters['keep_probability']))\n",
    "model.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "64/90 [====================>.........] - ETA: 1s - loss: 0.6914 - acc: 0.7656\n",
      "Epoch 00001: saving model to model.ckpt\n",
      "90/90 [==============================] - 5s 59ms/step - loss: 0.6903 - acc: 0.8148 - val_loss: 0.6835 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.6828 - acc: 0.9193\n",
      "Epoch 00002: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 0.6799 - acc: 0.9370 - val_loss: 0.6680 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.6659 - acc: 0.9245\n",
      "Epoch 00003: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 0.6605 - acc: 0.9389 - val_loss: 0.6365 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.6334 - acc: 0.9375\n",
      "Epoch 00004: saving model to model.ckpt\n",
      "90/90 [==============================] - 4s 40ms/step - loss: 0.6195 - acc: 0.9389 - val_loss: 0.5571 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.5295 - acc: 0.9688\n",
      "Epoch 00005: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 0.5233 - acc: 0.9389 - val_loss: 0.3715 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.3715 - acc: 0.9401\n",
      "Epoch 00006: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 36ms/step - loss: 0.3584 - acc: 0.9389 - val_loss: 0.1886 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.2624 - acc: 0.9479\n",
      "Epoch 00007: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 38ms/step - loss: 0.2718 - acc: 0.9389 - val_loss: 0.1137 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.2574 - acc: 0.9297\n",
      "Epoch 00008: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 37ms/step - loss: 0.2374 - acc: 0.9389 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.2198 - acc: 0.9401\n",
      "Epoch 00009: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 0.2197 - acc: 0.9370 - val_loss: 0.0552 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "64/90 [====================>.........] - ETA: 0s - loss: 0.2364 - acc: 0.9349\n",
      "Epoch 00010: saving model to model.ckpt\n",
      "90/90 [==============================] - 3s 35ms/step - loss: 0.2262 - acc: 0.9389 - val_loss: 0.0458 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1827790590>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=hypterparameters['batch_size'], epochs=hypterparameters['epochs'], \n",
    "          verbose=hypterparameters['is_verbose'], validation_split=hypterparameters['validation_split'], \n",
    "          callbacks=[ModelCheckpoint('model.ckpt', verbose=hypterparameters['is_verbose'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/c/8076/download/sample_submission.csv.zip\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')[:100]\n",
    "sample_submission[classes] = model.predict(X_test)\n",
    "sample_submission.to_csv('baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
