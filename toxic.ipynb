{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'validation_split': 0.1,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'embedding_size': 128,\n",
    "    'keep_probability': 0.9,\n",
    "    'lstm_size': 50,\n",
    "    'dense_size': 50,\n",
    "    'max_sequence': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/c/8076/download/train.csv.zip\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train_sentences = train.comment_text.values\n",
    "\n",
    "# Download from https://www.kaggle.com/c/8076/download/test.csv.zip\n",
    "test = pd.read_csv('data/test.csv')\n",
    "test_sentences = test.comment_text.values\n",
    "\n",
    "CLASSES = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "tokenizer.fit_on_texts(np.concatenate((train_sentences, test_sentences), axis=0))\n",
    "train_tokenized = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_tokenized = tokenizer.texts_to_sequences(test_sentences)\n",
    "vocab_size = len(Counter([token for sublist in train_tokenized + test_tokenized for token in sublist])) + 1\n",
    "\n",
    "X_train = sequence.pad_sequences(train_tokenized, maxlen=hyper_params['max_sequence'])\n",
    "y_train = train[CLASSES].values\n",
    "X_test = sequence.pad_sequences(test_tokenized, maxlen=hyper_params['max_sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, hyper_params['embedding_size']))\n",
    "model.add(LSTM(hyper_params['lstm_size']))\n",
    "model.add(Dropout(1 - hyper_params['keep_probability']))\n",
    "model.add(Dense(hyper_params['dense_size'], activation='relu'))\n",
    "model.add(Dropout(1 - hyper_params['keep_probability']))\n",
    "model.add(Dense(len(CLASSES), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/10\n",
      "143613/143613 [==============================] - 3091s 22ms/step - loss: 0.0650 - acc: 0.9788 - val_loss: 0.0509 - val_acc: 0.9815\n",
      "Epoch 2/10\n",
      "143613/143613 [==============================] - 3217s 22ms/step - loss: 0.0413 - acc: 0.9840 - val_loss: 0.0507 - val_acc: 0.9818\n",
      "Epoch 3/10\n",
      "143613/143613 [==============================] - 2974s 21ms/step - loss: 0.0323 - acc: 0.9872 - val_loss: 0.0514 - val_acc: 0.9815\n",
      "Epoch 4/10\n",
      "143613/143613 [==============================] - 3396s 24ms/step - loss: 0.0252 - acc: 0.9901 - val_loss: 0.0585 - val_acc: 0.9790\n",
      "Epoch 5/10\n",
      "143613/143613 [==============================] - 3323s 23ms/step - loss: 0.0191 - acc: 0.9925 - val_loss: 0.0712 - val_acc: 0.9778\n",
      "Epoch 6/10\n",
      "143613/143613 [==============================] - 3329s 23ms/step - loss: 0.0143 - acc: 0.9944 - val_loss: 0.0848 - val_acc: 0.9778\n",
      "Epoch 7/10\n",
      "143613/143613 [==============================] - 3349s 23ms/step - loss: 0.0110 - acc: 0.9958 - val_loss: 0.0879 - val_acc: 0.9773\n",
      "Epoch 8/10\n",
      "143613/143613 [==============================] - 3341s 23ms/step - loss: 0.0089 - acc: 0.9967 - val_loss: 0.0992 - val_acc: 0.9765\n",
      "Epoch 9/10\n",
      "143613/143613 [==============================] - 3345s 23ms/step - loss: 0.0072 - acc: 0.9973 - val_loss: 0.1115 - val_acc: 0.9770\n",
      "Epoch 10/10\n",
      "143613/143613 [==============================] - 3355s 23ms/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.1133 - val_acc: 0.9766\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=hyper_params['batch_size'], epochs=hyper_params['epochs'], \n",
    "                    validation_split=hyper_params['validation_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/c/8076/download/sample_submission.csv.zip\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "sample_submission[CLASSES] = model.predict(X_test)\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
